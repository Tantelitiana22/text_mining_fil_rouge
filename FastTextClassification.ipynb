{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import regex\n",
    "import re\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score,roc_curve,auc\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder,LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "import fastText\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fonction_nettoyage_text(df):\n",
    "    # supprission des ponctuations\n",
    "    rm_ponct = str.maketrans('','',string.punctuation)\n",
    "    df = df.apply(lambda x:x.translate(rm_ponct))\n",
    "    # suppression les unicodes\n",
    "    df = df.apply(lambda x:x.encode(\"ascii\",\"ignore\").decode(\"utf-8\"))\n",
    "                                                \n",
    "    # suppression des URLs\n",
    "    df = df.apply(lambda x:re.sub(r'http\\S+',\"\",x))\n",
    "    \n",
    "    # suppression des stopwords\n",
    "    stop_en = stopwords.words(\"english\")\n",
    "    df = df.apply(lambda x:\" \".join(x.lower() for x in np.str(x).split() if x.lower() not in stop_en))\n",
    "                                                  # Lemmatisation\n",
    "    df = df.apply(lambda x:\" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "                  \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import des données\n",
    "dataset = pd.read_csv(\"data_set_version_final.csv\")\n",
    "dataset.resume=fonction_nettoyage_text(dataset.resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,y_test = train_test_split(dataset.resume,dataset.Labels,test_size=0.3,shuffle=True)\n",
    "x_train,x_val,y_train,y_val = train_test_split(X_train,Y_train,test_size=0.3,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exporter les données train /test/val:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tantely/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/tantely/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n",
      "/home/tantely/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "x_train.to_csv(\"FastTestFolder/xtrain.txt\",index=False)\n",
    "x_val.to_csv(\"FastTestFolder/xval.txt\",index=False)\n",
    "X_test.to_csv(\"FastTestFolder/Xtest.txt\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.wrappers.fasttext import FastText as FT_wrapper\n",
    "from gensim.test.utils import datapath\n",
    "ft_home = '/home/tantely/fastText-0.2.0/fasttext'\n",
    "corpus_file=datapath(\"/home/tantely/Documents/INSA_Rouen/Projet_fil_rouge/text_mining_fil_rouge/FastTestFolder/xtrain.txt\")\n",
    "\n",
    "model_wrapper = FT_wrapper.train(ft_home, corpus_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=9357, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avantage de fast text:\n",
    "Peut supporter des mots qui ne se trouvent pas dans notre liste de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[ 2.8440485  -0.3145254   2.9473984  -2.2409658  -1.785316    0.9607362\n",
      " -0.2517628   1.1966292   4.514769    3.077068   -4.416133   -3.7850533\n",
      "  2.833843    5.7973423   2.2054873   4.5341954   2.388404   -1.5108497\n",
      "  0.28548536  2.0263388   1.0194411  -3.0406046   0.9812421  -4.752426\n",
      "  0.34504375  1.8508389  -1.4623685   1.7183746   1.1546805   0.01977971\n",
      "  2.4899638  -1.5656605   3.1972237  -1.1130537  -1.8690281  -1.8412724\n",
      "  0.7184055   2.5656836  -1.9896026  -1.330899    6.5645022   1.5740051\n",
      " -1.162449    4.3562365   0.16167136  0.424391   -1.0717667  -1.3347007\n",
      "  0.35180995 -1.9359143  -4.4474506  -3.8360472   1.2588416  -1.1305274\n",
      "  0.08190229 -1.3002462   2.2007837  -1.8586224   0.13748406  2.3846262\n",
      "  5.456688   -0.4895157  -1.0838895  -0.4587656  -0.7678471   0.09323923\n",
      " -1.1486492  -1.9001313   1.5670806  -0.5555484   0.5369114   5.5512257\n",
      "  0.12485618 -2.1108449   2.6695652   1.3240292   1.8632029  -1.4829787\n",
      " -2.466988    1.7188859   1.9109416  -0.33552817  2.7815273  -1.7661748\n",
      "  2.9403608   1.568924   -1.563147   -3.0430784  -4.562081   -4.179783\n",
      " -0.25777936 -1.331029    1.9786855  -2.655781    3.601377   -0.9349315\n",
      "  1.6607426   2.8369808   0.5187369  -2.1071377 ]\n",
      "False\n",
      "[ 0.6696784  -0.9164176  -0.35182843 -1.0234926  -1.3741497   1.8419933\n",
      " -0.63152134  1.0139802   1.0304519  -0.08306415 -1.2884043   1.2460698\n",
      " -0.24737477  0.01139552 -0.93221265  1.9817054  -0.821616   -0.7448915\n",
      " -0.250141   -0.1434976  -0.3451715  -0.540292    0.72566825  0.49788\n",
      "  0.93523353 -0.09692063  0.04298353 -0.7491132  -0.20741294 -0.08472943\n",
      "  1.2838298   0.21005376 -0.9052414   0.59668076 -1.0510578   1.0742179\n",
      "  1.0447615   0.8397992  -0.1663764   0.9461745   0.15737379  0.72093344\n",
      " -0.80184346  0.4139449   1.0451682  -0.92839336 -0.17343663 -0.44497022\n",
      " -1.1500026  -0.39104795 -1.0621194   0.07891925 -2.226269   -0.6648221\n",
      "  0.19276115  1.915702    0.9788046  -0.5182147  -0.06548026  0.60877115\n",
      "  0.2374612  -0.25001693 -0.08365421  0.80123585 -0.39815164 -0.92175615\n",
      "  0.06306877  0.63563836 -0.50530535  0.51034874 -0.8071284   1.8231077\n",
      "  0.8683401  -0.44259596 -1.3341377   0.6475976  -1.2258931  -1.1383739\n",
      "  0.25068763  2.1782823   0.12065884 -1.0663984   0.8985404   0.689758\n",
      " -0.245252   -0.14971279 -0.4471929  -0.6936857   0.5611871  -2.0166535\n",
      " -1.4245808  -0.30346414 -1.0553153  -0.05933772 -0.49076054 -1.8334981\n",
      " -0.41449496 -0.62158096  1.2692792   0.6751418 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"date\" in model_wrapper.wv.vocab)\n",
    "print(model_wrapper['data'])\n",
    "print(\"detla\" in model_wrapper.wv.vocab)\n",
    "print(model_wrapper['detla'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut alors calculer la similarité de deux mots sans même si l'un des deux mots ne se trouvent pas dans le corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19936287"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"data\" in model_wrapper.wv.vocab)\n",
    "print(\"detla\" in model_wrapper.wv.vocab)\n",
    "model_wrapper.similarity(\"data\", \"detla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opération sur la similarité des mots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sasdata', 0.9555476903915405),\n",
       " ('datasets', 0.936911940574646),\n",
       " ('databricks', 0.9342582821846008),\n",
       " ('etldata', 0.9209719300270081),\n",
       " ('exadata', 0.9162241220474243),\n",
       " ('metadata', 0.9017711877822876),\n",
       " ('voicedata', 0.8847713470458984),\n",
       " ('teradata', 0.8515818119049072),\n",
       " ('datadriven', 0.8462375402450562),\n",
       " ('datastage', 0.8400782346725464)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.most_similar(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfasttext import FastText\n",
    "import numpy as np\n",
    "class FastWord2Vec:\n",
    "    def __init__(self,inputFile,outputFile,epoch,lr,dim):\n",
    "        self.inputFile=inputFile\n",
    "        self.outputFile=outputFile\n",
    "        self.epoch=epoch\n",
    "        self.dim=dim\n",
    "        self.lr=lr\n",
    "        global model\n",
    "        \n",
    "    def __average_word(self,X,modelWords):\n",
    "        np.array([\n",
    "            np.mean([self.get_numpy_sentence_vector(w) for w in words.split() if w in modelWords]or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        X.to_csv(self.inputFile,index=False)\n",
    "        self.model=FastText().cbow(input=self.inputFile,output=self.outputFile,epoch=self.epoch,lr=self.lr,dim=self.dim)\n",
    "        return self\n",
    "    def transform(self,X,y):\n",
    "        return self.__average_word(X,self.words)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tantely/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "cbowTransformer=FastWord2Vec(inputFile='FastTestFolder/xtrain.txt',outputFile='model',epoch=10,lr=0.5,dim=100)\n",
    "cbowTransformer.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
